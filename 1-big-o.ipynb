{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1575c6",
   "metadata": {},
   "source": [
    "## Big O\n",
    "\n",
    "Big O, in the way industry tends to use it, is the tightest description of the bound of runtime.\n",
    "\n",
    "<img src=\"assets/big-o-complexity.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7e46d",
   "metadata": {},
   "source": [
    "#### Time Complexity\n",
    "\n",
    "Think of the analogy of transferring a hard drive to a friend:\n",
    "- Electronic Transfer: O(s), where s is thee size of the file. Time to transfer increases linearly with time.\n",
    "- Airplane Transfer: O(1) with respect to size of file. The size of the file is irrelevant to the transfer time.\n",
    "\n",
    "Linear will always at some point surpass constant! Common runtimes (in order of runtime complexity):<br>\n",
    "O(1) < O(log n) < O(n) < O(n log n) < O($n^{2}$) < O($2^{n}$) < O(n!)\n",
    "\n",
    "#### Academia Big O\n",
    "Academics describe runtimes in a few ways:\n",
    "- **O (big O)**: Describes the upper bound on the time. An algorithm that prints an array could be described as O(n) but also as O($n^2$), O($n^3$), etc. Similar to less-than-or-equal-to relationship.\n",
    "- **Ω (big omega)**: Equivalent concept but for lower bound. Ω(n) could also be Ω(log n) or Ω(1).\n",
    "- **Θ (big theta)**: In academia, Θ means both O and Ω. An algorithm that is Θ(N) is both O(n) and Ω(n)\n",
    "    - This is closer to industry's definition\n",
    "\n",
    "#### Best/Worst/Expected Case\n",
    "From the perspective of quick sort:\n",
    "- **Best Case**: If all elements are equal, traverses through array once. *O(n)*\n",
    "- **Worst Case**: The pivot is repeatedly the biggest element (pivot is randomly chosen as first element and every element is larger). *O($n^2$)*\n",
    "- **Expected Case**: *O(n log n)*\n",
    "\n",
    "We rarely discuss best case, after all, many special cases for algorithms can be O(1) best case.\n",
    "\n",
    "**For many - probably most - algorithms, the worst case and the expected case are the same.** Sometimes they are different though, and we need to describe both runtimes.\n",
    "\n",
    "\n",
    "### Space Complexity\n",
    "The amount of memory - or space - an algorithm requires is important too. If we create an array of size n, we require O(n) space, a 2 dimensional array of size n by n will require O($n^2$) space. *Stack space in recursive calls counts too*. For example, the code below would take O(n) time and O(n) space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45630bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_int(5)\n",
      "sum_int(4)\n",
      "sum_int(3)\n",
      "sum_int(2)\n",
      "sum_int(1)\n",
      "sum_int(0)\n"
     ]
    }
   ],
   "source": [
    "def sum_int(n):\n",
    "    print(f\"sum_int({n})\")\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    return n + sum_int(n-1)\n",
    "\n",
    "sum_int(5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a1d63",
   "metadata": {},
   "source": [
    "However, n calls doesn't necessarily mean O(n) space. Consider below, where there are O(n) calls to pairSum. However, those calls do not exist simultaneously on the stack, so you only need O(1) space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4270fd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pairSum(a, b):\n",
    "    return a + b\n",
    "\n",
    "def pairSumSequence(n):\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum += pairSum(i, i+1)\n",
    "    return sum\n",
    "\n",
    "pairSumSequence(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8645db",
   "metadata": {},
   "source": [
    "#### Drop the Constants\n",
    "\n",
    "Big O describes the rate of increase, therefore we can drop the constants in runtime, i.e. there is no O(2n) just O(n). For example, a code with two non-nested for loops is equivalent to a loop with a single for loop in Big O notation.\n",
    "\n",
    "#### Drop the Non-Dominant Term\n",
    "\n",
    "- O($n^2$ + n) becomes O($n^2$)\n",
    "- O(N + log n) becomes O(n)\n",
    "- O(5*$2^n$ + $n^100$) becomes O($2^n$)\n",
    "\n",
    "\n",
    "Multi-Part Algorithms: Add vs. Multiply\n",
    "\n",
    "- **Add**: Do this, then when you're done, do that - O(a+b)\n",
    "- **Multiply**: Do this for each time you do that - O(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3af49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition case\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "Multiplication case\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "2 0\n",
      "2 1\n",
      "2 2\n"
     ]
    }
   ],
   "source": [
    "# Add the two below - O(a+b)\n",
    "print(\"Addition case\")\n",
    "for a in range(3):\n",
    "    print(a)\n",
    "    \n",
    "for b in range(3):\n",
    "    print(b)\n",
    "\n",
    "# Multiply the nested for loop - O(a*b)\n",
    "print(\"Multiplication case\")\n",
    "for a in range(3):\n",
    "    for b in range(3):\n",
    "        print(a, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2e224",
   "metadata": {},
   "source": [
    "#### Amortized time\n",
    "\n",
    "Amortized time is a concept which takes into account both the fact that the worst case happens every once in a while, but once it happens, it won't happen for so long that the cost is 'amortized'.\n",
    "- Can also be considered as the **average time taken per operation, if you do many operations**\n",
    "\n",
    "Consider an ArrayList:\n",
    "- When an ArrayList reaches capacity, it will create a new array with double the capacity and copy all elements over - **O(n)** time\n",
    "- However, the vast majority of the time, adding will take **O(1)** time\n",
    "\n",
    "Deriving these complexities:\n",
    "- After adding X elements, the doubling takes 1, 2, 4, 8, 16, 32, 64, X copies\n",
    "- Reading this backwards it is x + x/2 + x/4 + x/8 + ... + 1 ~ 2x\n",
    "\n",
    "Therefore, we describe the complexity by stating that x adds take O(x) time and the amortized time for each adding is O(1).\n",
    "\n",
    "\n",
    "#### Log N Runtimes\n",
    "Look at binary search for an example. Looking for x in a sorted array, by first comparing x to the midpoint of the array and then searching the left or right half depending on whether x is less than or greater than the midpoint.\n",
    "```\n",
    "Search 9 within {1, 5, 8, 9, 11, 13, 15, 19, 21}\n",
    "    compare 9 to 11 -> smaller\n",
    "    search 9 within {1, 5, 8, 9}\n",
    "        compare 9 to 8 -> bigger\n",
    "        search 9 within {9}\n",
    "            compare 9 to 9\n",
    "            return\n",
    "```\n",
    "\n",
    "We start off with an N-element array and cut in half every step. When you see a problem where the number of elements in the problem space is halved each time, this is likely O(log n). <br>\n",
    "Mathematical derivation: <br>\n",
    "- N = 16, N = 8, N = 4, N = 2, N = 1\n",
    "     - How many times do we have to multiply by 2 to get to 16? 4 times. \n",
    "         - $2^4$ = 16 - > $log_2$(16) = 4\n",
    "         - $log_2$(n) = k -> $2^k$ = n\n",
    "         \n",
    "#### Recursive Runtimes\n",
    "\n",
    "Consider the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2c2e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def f(n):\n",
    "    if n <= 1:\n",
    "        return 1;\n",
    "    return f(n-1) + f(n-1)\n",
    "\n",
    "print(f(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb726e5d",
   "metadata": {},
   "source": [
    "Don't get fooled into thinking that it's O($n^2$). Each node (i.e. function call has two children). This can be expressed as $2^0$ + $2^1$ + $2^2$ + $2^3$ + ... + $2^{n-1}$ (which is $2^n$ - 1) nodes. In this case, this gives us **O($2^n$)**. The space complexity of the algorithm is O(n), because only O(n) nodes exist at any given time. (see table/figure in book for a good visualization). <br>\n",
    "- When you have a recursive function that makes multiple calls, runtime will often look like **O($branches^{depth}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f526463",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
